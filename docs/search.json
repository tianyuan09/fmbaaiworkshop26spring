[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FMBA AI Workshop Jan 2026",
    "section": "",
    "text": "Welcome",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#upcoming-sessions",
    "href": "index.html#upcoming-sessions",
    "title": "FMBA AI Workshop Jan 2026",
    "section": "Upcoming Sessions",
    "text": "Upcoming Sessions\nThe first 3 sessions on AI Tools Users have been completed in December 2025.\nBelow are the upcoming sessions:\n\nSession 4: Vibe Coding — January 16\nSession 5: Prototyping with AI — January 23\nSession 6: Building AI Powered Applications — January 30\n\n\n\n\n\n\n\nImportant\n\n\n\nYou must have a GitHub account to participate in the upcoming sessions effectively.\n\n\nPlease do not cite or distribute without author’s permission.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "chapter0.html",
    "href": "chapter0.html",
    "title": "1  AI Tools for Coding",
    "section": "",
    "text": "1.1 AI Tools for Text, Voice and Image Generation\nAI tools for text, voice, and image generation have become widespread.\nWe covered many of them in the first 3 AI workshops.\nText Generation: - ChatGPT - Claude - Microsoft Copilot - Google Gemini\nImage Generation: - DALL-E - Midjourney\nVoice & Synthesis: - NotebookLM – synthesizes and transforms information into podcasts and voice summaries",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>AI Tools for Coding</span>"
    ]
  },
  {
    "objectID": "chapter0.html#ai-tools-for-code-generation",
    "href": "chapter0.html#ai-tools-for-code-generation",
    "title": "1  AI Tools for Coding",
    "section": "1.2 AI Tools for Code Generation",
    "text": "1.2 AI Tools for Code Generation\nHowever, the world of coding requires a specialized set of tools designed specifically to understand, generate, and debug code for developers, programmers, engineers, etc.\n\nGitHub Copilot – AI pair programmer integrated into IDEs (e.g., VS Code) for real-time code suggestions and completion\nClaude Code – Coding-focused AI that analyzes and edits code across entire projects\nGemini Code / Gemini CLI – Google’s AI coding agent designed to work directly in the terminal\nOpenAI Codex – AI engine that writes, runs, and tests code in controlled development environments\nCursor – AI-powered code editor optimized for UI and end-to-end code generation workflows\n\nMany coding AI tools are accessed through CLIs (command-line interfaces), APIs (application programming interfaces) and professinal development environments, which require basic coding and terminal skills to use.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>AI Tools for Coding</span>"
    ]
  },
  {
    "objectID": "chapter1.html",
    "href": "chapter1.html",
    "title": "2  What is Vibe Coding",
    "section": "",
    "text": "2.1 How It Works\n“Vibe coding” is an AI-assisted software development technique introduced by Andrej Karpathy (a co-founder of OpenAI) in February 2025.\nThe term quickly gained recognition among software developers, AI practitioners, and tech media.\nReference Reading\nTraditional Coding: A human types: print(\"Hello World\").\nAI-Assisted Coding: A human types half a line, and the AI suggests the rest (auto completion).\nVibe Coding: It is a software creation approach where developers describe tasks to a large language model, rely on it to generate code, and evaluate results through execution rather than reviewing or editing the code.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is Vibe Coding</span>"
    ]
  },
  {
    "objectID": "chapter1.html#vibe-coding-an-example",
    "href": "chapter1.html#vibe-coding-an-example",
    "title": "2  What is Vibe Coding",
    "section": "2.2 Vibe Coding: An Example",
    "text": "2.2 Vibe Coding: An Example\n\nA human says, “I want an web app that tracks our Q3 sales goals and sends a Slack alert if we drop below 80%.”\nThe AI then autonomously writes the code, sets up the server, connects the database, and fixes its own bugs.\nThe human only need to know how to run the code to test whether it is working as expected.\nIf not, the human keeps asking for revisions in natural language instead of inspecting or modifying the code itself.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is Vibe Coding</span>"
    ]
  },
  {
    "objectID": "chapter1.html#is-coding-skills-required",
    "href": "chapter1.html#is-coding-skills-required",
    "title": "2  What is Vibe Coding",
    "section": "2.3 Is Coding Skills Required?",
    "text": "2.3 Is Coding Skills Required?\n\n\n\n\n\n\nImportantCoding Skills Is Still Required\n\n\n\nVibe coding lowers the barrier, but it does not remove the need for technical literacy.\nVibe coding reduces how much code you write, not how much responsibility you have.\n\n\nWhy This Matters:\n\nYou must run and test the code — real apps don’t run inside chat; they run in terminals, servers, or browsers\nYou need to validate outcomes — knowing what “working” looks like requires understanding logs, errors, and outputs\nAI-generated code can fail silently — without basic coding knowledge, you won’t know whether results are correct or misleading\nDebugging still happens — even if AI writes the code, humans must recognize when something breaks and why\nSecurity and data risks remain — you need enough literacy to spot unsafe behaviors (e.g., exposed keys, wrong data access)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is Vibe Coding</span>"
    ]
  },
  {
    "objectID": "chapter1.html#minimal-technical-skills-required-for-vibe-coding",
    "href": "chapter1.html#minimal-technical-skills-required-for-vibe-coding",
    "title": "2  What is Vibe Coding",
    "section": "2.4 Minimal Technical Skills Required for Vibe Coding",
    "text": "2.4 Minimal Technical Skills Required for Vibe Coding\n\nRun code in professional environments\n\nUse VS Code, GitHub Codespaces, and cloud runtimes\nUnderstand how to start, stop, and rerun applications\n\nBasic operating system & terminal literacy\n\nNavigate files and folders (Linux basics)\nUse terminal commands\n\nUnderstand core code artifacts\n\nWhat is a python script file?\nKnow the difference between .py files and Jupyter notebooks\n\nClear product thinking\n\nHave a concrete idea or prototype in mind before prompting\nBreak ideas into steps the AI can execute\n\nVersion control with Git (your regret medicine)\n\nSave working versions; roll back when the AI makes mistakes",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is Vibe Coding</span>"
    ]
  },
  {
    "objectID": "chapter2.html",
    "href": "chapter2.html",
    "title": "3  Labs: Minimal Technical Skills Required",
    "section": "",
    "text": "3.1 Lab: GitHub Codespaces",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Labs: Minimal Technical Skills Required</span>"
    ]
  },
  {
    "objectID": "chapter2.html#lab-github-codespaces",
    "href": "chapter2.html#lab-github-codespaces",
    "title": "3  Labs: Minimal Technical Skills Required",
    "section": "",
    "text": "3.1.1 Objective\n\nUse GitHub Codespaces, VS Code, and cloud runtimes.\nUnderstanding Terminal, Command Line Interface (CLI), and user interface.\n\n\n\n3.1.2 Task\n\n\n\n\n\n\nTipTask: Get Started with GitHub Codespaces\n\n\n\nFollow the steps in the document below to learn GitHub Codespaces basics and get comfortable with the professional development environment.\n\nStep-by-step lab: Get Started With GitHub Codespaces\n\n\n\nAfter completing the lab, answer these questions:\n\nWhat is a GitHub Codespace and how does it differ from working on your local machine?\nHow do you access the terminal in a Codespace?\nWhere can you find the GitHub Copilot (coding assistant) in Codespaces?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Labs: Minimal Technical Skills Required</span>"
    ]
  },
  {
    "objectID": "chapter2.html#lab-basic-operating-system-terminal-literacy",
    "href": "chapter2.html#lab-basic-operating-system-terminal-literacy",
    "title": "3  Labs: Minimal Technical Skills Required",
    "section": "3.2 Lab: Basic Operating System & Terminal Literacy",
    "text": "3.2 Lab: Basic Operating System & Terminal Literacy\n\nNavigate files and folders (Linux basics)\nUse terminal commands to start, stop, and rerun applications\n\n\n3.2.1 Command Line and Terminal\n\nBefore learning a full programming language like Python, many computer science students first encounter the terminal and command line. In practice, the command line acts as a student’s first scripting language: it teaches how to run programs, navigate files, pass arguments, and control how code executes.\nWhile modern notebook environments (e.g., Google Colab or Jupter Notebooks) make it easy to start Python coding without setup, they often hide this foundational layer. As a result, students may write Python without ever learning how real programs are stored, executed, and managed using .py files and the terminal—skills that are essential for real-world development, servers, and production systems.\n\n\n\n\n\n\nWarning⚠️ Importance of Command Line and Terminal\n\n\n\nIf you skip learning command line skills or avoid the terminal, you’ll struggle to work on real-world projects, collaborate effectively with teams, or operate in servers or cloud platforms — where graphical interfaces aren’t available. The terminal isn’t just a tool for experts; it’s the foundation for professional workflows in data science and engineering.\n\n\nSo, before diving deeper into advanced business data workflows, we’ll start by filling this gap, and learn the command lines and terminal to navigate files, run Python scripts, and operate in professional computing environments.\nWhat You’ll Learn Next\n\nMain operating systems: Windows, macOS, Linux/Unix\nGUI vs terminal and why terminals matter\nBash shell basics for programming and data science\n\n\n\n3.2.2 Operating Systems Overview\nMost students in this course use Windows, which dominates personal computers with roughly 70–75% of the global desktop market. macOS holds about 15–20%, while Linux and others make up a small share of personal use.\nIn contrast, the enterprise, cloud, AI/ML, and high-performance computing (HPC) worlds are very different. Linux and other Unix-like systems are the backbone in web servers, cloud computing and supercomputers, making up nearly half of cloud workloads and being the OS for all top 500 supercomputers. Popular Unix and Linux systems include:\n\nUbuntu\nDebian\nFedora\nRed Hat Enterprise Linux (RHEL)\n\n\n\n\n\n\n\nNotemacOS is Unix-based\n\n\n\nAlthough macOS looks different, it is actually Unix-based, meaning the terminal commands and Bash shell you’ll learn in this course work much the same on both macOS and Linux.\n\n\n\nServers Linux holds a 62.7% market share for server operating systems.\n\nWeb servers: 77–88% of public web servers run on Linux or other Unix-like systems. It is the most used operating system for web servers globally.\n\nCloud computing Cloud workloads are heavily dependent on Linux-based operating systems. As of mid-2025, Linux powers 49.2% of all global cloud workloads.\nSupercomputers Linux has a complete monopoly in the supercomputing sector. 100% market share: Since 2017, 100% of the world’s top 500 supercomputers have run on Linux.\nAI and ML workloads Linux is the clear leader for AI and ML projects and infrastructure. In mid-2025, 87.8% of machine learning workloads ran on Linux infrastructure. Large ML and data science deployments predominantly run on Linux-based or Unix-based servers.\n\nCloud environments: Cloud providers like AWS, Google Cloud (GCP), and Microsoft Azure primarily offer Linux-based instances for running AI and ML tasks.\n\n\nSource: Wikipedia - Usage share of operating systems Azure Official Page, Microsoft Tech Community Update (Feb 2025)\n\n\n3.2.3 What Operating System does GitHub Codespaces use?\nOpen the Terminal inside your GitHub Codespace (View → Terminal) and check the OS with the commands below.\n# Bash\n# Display info about the operating system\ncat /etc/*-release\n\n# Display the Linux kernel version and build info\ncat /proc/version\nYou should see an Ubuntu-based Linux release because GitHub Codespaces runs inside a Linux container.\n\n\n3.2.4 What Is a Terminal?\n\nA terminal (also called a command line or shell) is a text-based interface that lets you interact directly with your computer by typing commands.\nBefore graphical interfaces (with windows, icons, and a mouse) were invented, the terminal was the primary way users operated computers — to run programs, manage files, and control hardware.\nEVERY operating system includes a terminal app:\n\nWindows:\n\nCommand Prompt(cmd)\nPowerShell\nor Bash (through Windows Subsystem for Linux)\nLinux: Bash is the default shell on most Linux systems\n\nmacOS: Zsh in Terminal app (based on Unix) is the default terminal in macOS.\n\n\n\n\n\n\n\nNoteBash vs Zsh\n\n\n\n\nBoth Bash and Zsh are terminals that interpret your commands, and they work almost the same.\n\n\n\n\nThe terminal can do almost everything you normally do with a mouse:\n\nNavigate files and folders\n\nRun programs or scripts\n\nInstall and manage software\n\nConnect to remote servers\n\nAutomate repetitive tasks with shell scripts\n\nData scientists and developers rely on the terminal for its speed and automation, especially when working in cloud environments like GitHub Codespaces or on Linux servers.\n\n\n3.2.5 Why Learn Bash commands and Terminal?\nFirst, data science projects often run on servers or cloud environments, not personal laptops which lack the computational power for large-scale training, data processing, or deployment.\nThese servers — such as AWS EC2, Azure VMs, or Google Cloud Compute instances — usually run Linux or Unix systems and don’t include a graphical user interface (GUI) by default. — they are managed entirely through the command line interface (CLI). To interact with them efficiently, you use Bash, a powerful and widely used command-line shell.\n\n\n\n\n\n\nTipWhat is a GUI?\n\n\n\nA Graphical User Interface (UI) is the visual part of your computer — windows, buttons, and menus you click with the mouse. However, Linux servers don’t usually have this kind of visual interface.\nInstead, users interact with them through script commands typed into a terminal such as bash.\n\n\n\n\n3.2.6 GUI, CLI, Terminal and Desktop\n\n\nGUI (Graphical User Interface) – The visual interface you use with a mouse, icons, and windows, such as Windows desktop, macOS Finder. GUIs are user-friendly but less efficient for automation or remote access.\nCLI (Command Line Interface) – A text-based interface where you type commands instead of clicking.\nTerminal – The program that provides access to the CLI. It’s like a window that lets you type commands and see text output, such as Windows PowerShell, macOS Terminal, Linux bash Terminal.\nDesktop Environment – The collection of GUI components that make up the user’s graphical workspace — including the taskbar, file explorer, and app windows; such as Windows Desktop, macOS.\n\n\n\n\n\n\n\nNoteSummary\n\n\n\n\nThe Terminal gives you access to the CLI, while the Desktop Environment provides a GUI.\n\nBoth let you control the same computer — one through text, the other through graphics.\n\n\n\n\n\n3.2.7 Learning Bash commands in GitHub Codespaces\nMastering Bash is essential. It enables you to write scripts, manage jobs, and execute commands directly on compute servers — a critical skill when working with large datasets or LLM pipelines.\n\n\n3.2.8 Bash in VS Codespaces\nRestart your GitHub Codespaces.\n\nMake sure you can see the Terminal panel. If you accidently closed your terminal, you can always start one (or many) following the steps below.\n\nYou also can start a second terminal via the Terminal panel.\n\nWe are going to learn basic bash commands to:\n\nNavigate and manage files\nRun Python (.py) scripts directly from the command line\nWork efficiently within server-based or local terminal environments\n\nUse your GitHub Codespace terminal in VS Code to practice these commands. If you close the terminal, reopen it via View → Terminal or the Ctrl+` shortcut.\n\n\n3.2.9 Lab: Linux and bash\n\nDisplay info about the operating system.\n\ncat /etc/*-release\n\nDisplay the Linux kernel version and build info.\n\ncat /proc/version\n\n\n3.2.10 Lab: Paths, Folders, Directories (pwd)\n\nPrint your current working directory (the folder you are “in”). A directory is a folder, directory and folder are the same thing.\n\npwd\n#/workspaces/codespaces-jupyter\nPlease type pwd 5 times and each time say “print working directory”.\nWhen to use pwd? if you lost in folders and don’t know where you are in the directories or folders, pwd will tell you where you are.\n\n\n3.2.11 Directory Structure in GitHub Codespace Terminal\n/\n├── bin/\n├── boot/\n├── dev/\n├── etc/\n├── home/\n│   └── codespace/          ← your user home directory if you do `cd ~`\n├── lib/\n├── lib64/\n├── media/\n├── mnt/\n├── opt/\n├── proc/\n├── root/\n├── run/\n├── sbin/\n├── srv/\n├── sys/\n├── tmp/\n├── usr/\n└── workspaces/\n    └── codespaces-jupyter     ← your GitHub repo (default working dir)\n\n\n\n3.2.12 Lab: List Directory (ls)\nThe ls command is used to list files and folders in a directory.\nHere are some of the most commonly used ones with options (such as -a, -l)\n# List files and folders in the current directory\nls\n\n# List **all** files, including hidden ones (those starting with .)\nls -a\n\n# List files in a detailed (**long**) format — shows permissions, owner, size, and date\nls -l\n\n# Combine options: show all files in detailed view\nls -la\n\n# Sort files by modification **time** (newest first)\nls -lt\n\n\n3.2.13 Lab: Change Directory (cd)\n\ncd data: go the data folder under the current directory (create it first if it doesn’t exist).\ncd ..: go the parent folder.\ncd ~: go to the home folder. In Codespaces, the home folder is /home/codespace. If you are lost in a directory and want to start over from a safe directory – your home. You can type cd ~, and you will be taken to the home directory.\n\n# go into a data folder under your repo root\nls\ncd data\nls\n# see the \"altantis.csv\"\n\n# Move up one folder (to the parent directory /workspaces/codespaces-jupyter)\ncd ..\n\n# Go back to your \"home\" folder (/home/codespace in Codespaces)\ncd ~\npwd\n\n# To-do: find a way to go back to the: workspaces/codespaces-jupyter. \n# If you failed, simply start a new terminal. \n\n\n3.2.14 Lab: Make A Directory (mkdir)\n# From your repo root, create a new folder named \"data\"\ncd /workspaces/codespaces-jupyter\nmkdir mydata\n\n# Make multiple folders at once\nmkdir project results logs\n\n# Check that they were created\nls\n\n\n3.2.15 Lab: Clear the Screen (clear)\n# Clear the terminal screen\nclear\n\n\n3.2.16 Lab: Remove Directory (rmdir)\n# Create an empty folder named \"temp_folder\"\nmkdir temp_folder\n\n# Remove the empty folder\nrmdir temp_folder\n\n# Create multiple empty folders and remove them\nmkdir folder1 folder2\nrmdir folder1 folder2\n\n\n3.2.17 Lab: Making Empty Files (touch)\n# Create an empty file named \"notes.txt\"\ntouch notes.txt\n\n# Create multiple files at once\ntouch a.txt b.txt c.txt\n\n# Verify files were created\nls\n\n\n3.2.18 Lab: Copy a File (cp)\n# Copy a file to a new file\ncp notes.txt notes_backup.txt\n\n# Create a folder to copy into\nmkdir backup\n\n# Copy a file into a different folder\ncp notes.txt backup/\n\n# Check the results\nls backup\n\n\n3.2.19 Lab: Moving/Rename a File (mv)\n# Move a file into a different folder\nmv notes_backup.txt backup/\n\n# Rename a file\nmv notes.txt todo.txt\n\n# Verify the changes\nls\n\n\n3.2.20 Lab: Stream a File (cat)\n# Display the contents of a file\ncat todo.txt\n\n# To-do: Display the README.md file in your repository:\n\n\n# Display a system file (try this!)\ncat /etc/*-release\n\n\n3.2.21 Lab: Removing a File (rm)\n# Create some temporary files first\ntouch old.txt temp.txt sample.txt\n\n# Remove a single file\nrm old.txt\n\n# Remove multiple files\nrm temp.txt sample.txt\n\n# Remove an entire folder and its contents (be careful!)\nrm -r backup\n\n\n3.2.22 Lab: Exiting Your Terminal (exit)\n# Exit the current terminal session\nexit\n\n\n3.2.23 Summary Table – Common Bash Commands\n\n\n\nCommand\nPurpose\nExample\n\n\n\n\npwd\nPrint working directory\npwd\n\n\nls\nList files and folders\nls -la\n\n\ncd\nChange directory\ncd /workspaces/codespaces-jupyter\n\n\nmkdir\nMake a new directory\nmkdir data\n\n\nrmdir\nRemove an empty directory\nrmdir temp_folder\n\n\ntouch\nCreate an empty file\ntouch notes.txt\n\n\ncp\nCopy a file\ncp notes.txt backup/\n\n\nmv\nMove or rename a file\nmv old.txt new.txt\n\n\ncat\nView contents of a file\ncat notes.txt\n\n\nrm\nRemove a file or folder\nrm -r foldername\n\n\nclear\nClear the screen\nclear\n\n\nexit\nExit the terminal\nexit\n\n\n\n\n\n3.2.24 Lab: create the scripts folder\nUsing the bash terminal to create a scripts folder under GitHub default working dir /workspaces/codespaces-jupyter, and create an empty my_script.py file in the scripts folder.\n\n\n\n\n\n\nTipTip\n\n\n\nYou may find the commands pwd, mkdir, ls, cd, and touch helpful for completing this exercise.\n\n\nYour task is to:\n\nVerify your current working directory.\n\nCreate a new folder called scripts inside the project root.\n\nList the directory contents to confirm that scripts was created successfully.\n\nNavigate into the scripts folder.\n\nConfirm it is empty.\n\nCreate a new Python file named my_script.py inside the scripts folder.\n\nWrite the Bash commands needed to accomplish each step.\nOnce you complete the task, your explorer should look like below:\n\n\n\n\n\n\n\nCautionSolution\n\n\n\n\n\n@tianyuan09 ➜ /workspaces/codespaces-jupyter (main) $ pwd\n/workspaces/codespaces-jupyter\n@tianyuan09 ➜ /workspaces/codespaces-jupyter (main) $ mkdir scripts\n@tianyuan09 ➜ /workspaces/codespaces-jupyter (main) $ ls\nREADME.md  _quarto.yml  bash.qmd  chapter0.qmd  chapter1.qmd  chapter2.qmd  chapter3.qmd  docs  images  index.qmd  references.bib  data  project  results  logs  scripts\n@tianyuan09 ➜ /workspaces/codespaces-jupyter (main) $ cd scripts\n@tianyuan09 ➜ /workspaces/codespaces-jupyter/scripts (main) $ ls\n@tianyuan09 ➜ /workspaces/codespaces-jupyter/scripts (main) $ touch my_script.py",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Labs: Minimal Technical Skills Required</span>"
    ]
  },
  {
    "objectID": "chapter2.html#lab-python-script-files-basics",
    "href": "chapter2.html#lab-python-script-files-basics",
    "title": "3  Labs: Minimal Technical Skills Required",
    "section": "3.3 Lab: Python Script Files Basics",
    "text": "3.3 Lab: Python Script Files Basics\n\n\n\n\n\n\nNoteObjectives\n\n\n\n\nWhat is a python script file?\nKnow the difference between .py files and Jupyter notebooks .ipynb.\n\n\n\nPython is a high-level, general-purpose programming language used for data science, AI/ML, automation, and software development.\n\nTwo common Python file types you will use:\n\n.py script files — plain-text Python source you run from the terminal (e.g., python hello.py) or import as modules.\n.ipynb Jupyter notebooks — interactive notebooks that mix code, text, and visuals; executed cell by cell inside VS Code or Jupyter.\n\n\n\n3.3.1 .ipynb Notebook vs .py Script Files\nFigure 3.1 illustrates the difference between running Python code in .ipynb notebook versus in `.py’ script file.\n\n\n\n\n\n\nFigure 3.1: Comparison of Jupyter Notebook and Python Script formats\n\n\n\nUnderstanding the Terminal\nSee directory structure in codespaces in the previous chapter.\nIn the terminal, it always starts with:\n\n@tianyuan09 ➜ /workspaces/codespaces-jupyter (main) $.\n\n@tianyuan09 ➜ /workspaces/codespaces-jupyter (main) $\n│           │                 │                   │\n│           │                 │                   └─ Prompt symbol ($): \n│           │                 │                      shows the terminal is ready for input\n│           │                 │\n│           │                 └─ Current working directory:\n│           │                    you’re inside the folder “codespaces-jupyter”\n│           │                    located under “/workspaces”\n│           │\n│           └─ Arrow (➜): \n│               just a decorative separator in the prompt\n│\n└─ Username (and sometimes host): \n   “tianyuan09” — the current user logged into this environment\nDifference between .ipynb Notebook and .py Script File.\n\n\n\n\n\n\n\n\nFeature\n.ipynb (Jupyter Notebook)\n.py (Python Script)\n\n\n\n\nStructure\nStructured JSON format combining code, text cells in Markdown, and outputs.\nPlain text file containing only Python code and comments #.\n\n\nExecution\nRun one cell at a time, showing output immediately below each cell.\nExecuted all at once using a command like python my_script.py, seen ④ in Figure 3.1.\n\n\nUse Case\nIdeal for data analysis, visualization, and teaching due to its interactive nature.\nBetter for automation, deployment of production-ready code.\n\n\n\n\n\n3.3.2 Lab: Create and run a .py script file\nFirst, let’s create a hello.py under the scripts folder.\n# file path: scripts/hello.py\nprint(\"Hello from Python!\")\nprint(\"This script is running from the terminal.\")\n\n# Get current date and time\nimport datetime\nnow = datetime.datetime.now()\nprint(f\"Current time: {now}\")\nYou can directly use explorer or use bash command Figure 3.2.\n\n\n\n\n\n\nFigure 3.2: Create and run your 1st script file\n\n\n\nExpected output:\nHello from Python!\nThis script is running from the terminal.\nCurrent time: 2026-01-13 10:30:45.123456\n\n\n\n3.3.3 Lab: Checking Your Python Version\n# Check Python version\npython --version\npython3 --version\n\n# Check which Python executable you're using\nwhich python\nwhich python3\n\n\n3.3.4 Lab: Different Python Commands\nDepending on your system setup, you might need to use different commands:\n# On systems with Python 3 as default\npython hello.py\n\n# OR\npython3 hello.py\n\n# OR Using specific Python version\npython3.9 hello.py\npython3.12 hello.py",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Labs: Minimal Technical Skills Required</span>"
    ]
  },
  {
    "objectID": "chapter2.html#running-scripts-in-different-directories.",
    "href": "chapter2.html#running-scripts-in-different-directories.",
    "title": "3  Labs: Minimal Technical Skills Required",
    "section": "3.4 Running Scripts in Different Directories.",
    "text": "3.4 Running Scripts in Different Directories.\n\n3.4.1 Absolute Paths\n# Run script from anywhere using absolute path\npython /Users/username/projects/my_script.py\n/Users/username/projects/my_script.py is a absolute file path.\nAbsolute paths:\n\nOn macOS/Linux, starts with /.\nOn Windows, starts with a drive letter like C:/.\nIn short, it always starts from the root of the filesystem (the top level).\n\nYou can find either the relative or aboslute file paths in codespaces:\n\n\n\n3.4.2 Relative Paths\n# Run script in current directory\npython ./script.py\n\n# Run script in subdirectory\npython scripts/data_analysis.py\n\n# Run script in parent directory\npython ../utilities/helper.py\nThe paths above (e.g. ../utilities/helper.py) are relative paths.\n\nThey don’t start with / or a drive letter (e.g. C:/).\nThey may include . (current folder) or .. (parent folder).\nThey starts from your current working directory (pwd).\n\n\n\n3.4.3 Difference in absolute vs relative paths\n\n\n\nStarts With\nType\nMeaning\n\n\n\n\n/ (Linux/Mac)\nAbsolute\nStarts at root of file system\n\n\nC:\\ (Windows)\nAbsolute\nStarts at root of drive\n\n\n. or ..\nRelative\nBased on current working directory\n\n\nNo / or C:\\\nRelative\nImplied to start from current folder",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Labs: Minimal Technical Skills Required</span>"
    ]
  },
  {
    "objectID": "chapter3.html",
    "href": "chapter3.html",
    "title": "4  Prototyping an app with streamlit",
    "section": "",
    "text": "4.1 Context and Goal\nYou are going to prototype an interactive financial dashboard app using Vibe Coding.\nData scientists often start in Jupyter Notebooks for exploration and analysis. However, real-world applications require deployable, interactive dashboards for sharing insights with others.\nYou are provided with the some preliminary analyses of financial data in Jupyter notebook. You are tasked to refactor it and create an Streamlit web application to present the data in an interactive way.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prototyping an app with `streamlit`</span>"
    ]
  },
  {
    "objectID": "chapter3.html#context-and-goal",
    "href": "chapter3.html#context-and-goal",
    "title": "4  Prototyping an app with streamlit",
    "section": "",
    "text": "ImportantGoal\n\n\n\nTransition from a prototype .ipynb file to a production-ready .py file that builds an interactive Streamlit dashboard.\n\n\n\n\n\nDownload the following files from the downloads folder in the https://github.com/tianyuan09/fmbaaiworkshop26spring.\n\nCompute Financial Ratios Notebook.ipynb – a Jupyter Notebook\nsp500_data.csv – Financial data.\nsp500_tickers.csv – List of tickers.\n\nCreate a folder named streamlit25 in the default directory using bash command.\nDrag these three files into this folder in your browser.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prototyping an app with `streamlit`</span>"
    ]
  },
  {
    "objectID": "chapter3.html#the-vibe-coding-setup",
    "href": "chapter3.html#the-vibe-coding-setup",
    "title": "4  Prototyping an app with streamlit",
    "section": "4.2 The Vibe Coding Setup",
    "text": "4.2 The Vibe Coding Setup\nYou are going to use VS Code with Copilot in Github codespaces to “vibe code” a dashboard web application. Let’s cover a few basics before you start.\n\nEach Github Codespace runs on a Linux virtual machine that already has tools like Python, Jupyter Notebook support, various packages, and VS Code (via the web interface) preinstalled. When you open a Codespace, you’re actually using VS Code running in your browser, connected to that remote Linux machine. So:\n\nCodespaces = a Linux system in the cloud + Python + JupyterLab + various Python packages + VS Code (IDE interface).\n\n\nYou also can set up the same development environment in your local PC. You will need to install multiple softwares and tools, such as Python, VS Code, Python extension in VS Code, and each python package that you might use (such as pandas).\n\n\n\n\n\n\n\n\nEnvironment\nWhat it includes\nNotes\n\n\n\n\nCodespaces\nLinux + Python + Jupyter + various packages + VS Code (web)\nCloud-hosted; nothing to install locally; runs VS code interface\n\n\nGoogle Colab\nLinux + Python + Jupyter + various packages\nCloud-hosted; focuses on notebook interface\n\n\nLocal PC\nWhatever you install (Python, VS Code, Jupyter)\nRuns directly on your machine\n\n\n\n\n4.2.1 GitHub Copilot and Copilot Chat: Ask, Edit and Agent Modes\nLet’s introduce the features of GitHub Copilot and Copilot Chat. GitHub Copilot comes with four distant modes that you may use:\n\nInline Chat or suggestions: quick in-context code suggestions directly within VS Code using shortcuts ⌘+I or Ctrl+I.\n\n\n\nAsk Mode: best for Q&A. Highlight some code, then ask Copilot questions about its logic, purpose, or braistorm ideas implementation.\nEdit Mode: give you inline, review-ready code edits across the files.\nAgent Mode: an autonomous mode where Copilot analyzes context (e.g., files in your workspace) and performs tasks based on your request.\n\n\n\n\n4.2.2 Tips for Using the Copilot Agent Mode\nTo get the best results in Agent Mode, you can provide additional context or use special commands to guide Copilot about what you want it to do.\n\n\n\n\n\n\nNoteWhat is “Context”?\n\n\n\nContext is the information you give Copilot so it understands what you’re working on and can respond more accurately. In Agent Mode, context can include the code you’ve selected, other .py files, or any extra notes you write with #.\n\n\n\nHighlight code (e.g., line 57-59 of the vscodecopilot.qmd file) in the file will automatically add those lines of code in the context (see Figure 4.1)\nAdd context with #. Add additional files that you want Copilot to read before completing the task.\ncommands with /. E.g. /explain is a command asking for explanation of the code.\n\n\n\n\n\n\n\nFigure 4.1: Highlight code, or add contexts or commands\n\n\n\n\n\n4.2.3 Vibe-coding vs AI-assisted Coding\nUsing the Agent Mode will allow you to vibe code without reading or understanding any of the code. You relied on the AI to produce something that looked right without knowing how it actually worked.\nHowever, if you read, wrote, or edited the code while building the app, you were doing AI-assisted coding — working with the AI to shape logic, fix bugs, and design structure.\n\n\n\n\n\n\n\n\nAspect\nVibe Coding\nAI-Assisted Coding\n\n\n\n\nDefinition\nA no-code workflow where you don’t read, write, or edit code. You simply test the prototype or app to see if it meets your design or intent.\nA coding workflow where you interact with and modify code using AI tools like Copilot’s Ask, Edit, or Inline Chat.\n\n\nGoal\nValidate the “vibe” — check if the prototype looks, feels, and behaves as intended.\nBuild, refine, and ship production-ready features with AI support.\n\n\nUser Interaction\nNo direct code manipulation — focus is on results, not implementation.\nActively generate, read, edit, debug, and review code and suggestions with AI\n\n\nAI Tools\nGitHub Copilot Agent Mode\nGitHub Copilot Ask Mode, Edit Mode, Inline Chat\n\n\nMindset\n“I don’t care how it’s built — does it look and work as intended?”\n“I’ll collaborate with AI to understand, fix, or enhance the code.”\n\n\nBest For\nRapid prototyping, early design validation\nFull-cycle software or data product development: feature implementation, optimization, and maintenance.\n\n\nLimitations.\nIgnores the complexity, lacks of consideration over performance, scalability, and maintainability.\nSupports real data engineering work but still requires developer understanding and validation\n\n\n\nBoth Vibe-coding and AI-assisted coding have their place in development. Use vibe-coding for quick validation and prototyping, and AI-assisted coding for building robust, production-ready data science solutions.\nAlthough vibe-coding feels exciting, you can’t rely on it from prototype to production, as it often makes mistakes or produces “shit code” — duplicated logic, buggy and insecure implementations, and tangled features no one dares to maintain. In data science, that might look like a notebook full of hard-coded file paths, random seeds, and global variables — impossible to reproduce or scale.\n\nAlso, don’t fool yourself into thinking you’re learning to code while working in Agent Mode — you’re NOT building the skills yourself. You can’t learn guitar just by watching someone else play, and you can’t learn piano by watching performances. Likewise, you can’t truly learn programming just by watching an Agent write code for you. The craft lies in understanding, experimenting, and making mistakes. That’s how you move from vibe-coding prototypes to engineered, production-ready solutions.\nWhile vibe coding can accelerate prototyping and help non-technical users validate design ideas, it often overlooks many critical aspects of data engineering — such as scalability, performance, maintainability, and security. Building reliable data science solution or product remains a complex, multi-layered process that requires thoughtful coding, testing, and collaboration between designers, developers, and AI tools.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prototyping an app with `streamlit`</span>"
    ]
  },
  {
    "objectID": "chapter3.html#lab-make-it-a-.py-file-with-functions",
    "href": "chapter3.html#lab-make-it-a-.py-file-with-functions",
    "title": "4  Prototyping an app with streamlit",
    "section": "4.3 Lab: Make it a .py file with functions",
    "text": "4.3 Lab: Make it a .py file with functions\nLet’s do some vibe coding!\n\n1. Open and take a look at the Compute Financial Ratios Notebook.ipynb\n2. Add a z-score metric seen in Figure 4.2.\n\n\n\n\n\n\n\nFigure 4.2: Z-score reference\n\n\n\n\n3. Make a empty finratios.py script file inside the same folder using bash command.\n4. Re-write the notebook code into reusable functions inside finratios.py\n\nfetch_data_local\nfetch_data_local_single_ticker\ncalculate_metrics\nplot_trend\n\n\nGood practices:\nYou can copy and paste the good practice to Copilot when completing the tasks above.\n\nEach function should do one clear thing (e.g., load data, compute metrics, or plot)\nWhen writing functions, only use variables that come from the input parameters. If you need to use something inside the function, then make them input parameters.\nAdd a if __name__ == \"__main__\": for testing at the bottom of finratios.py, such as:\n\nif __name__ == \"__main__\":\n    # Simple test cases\n    print(compute_pe_ratio(1000000, 50000, 30))",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prototyping an app with `streamlit`</span>"
    ]
  },
  {
    "objectID": "chapter3.html#learn-a-bit-about-streamlit",
    "href": "chapter3.html#learn-a-bit-about-streamlit",
    "title": "4  Prototyping an app with streamlit",
    "section": "4.4 Learn a bit about Streamlit",
    "text": "4.4 Learn a bit about Streamlit\n\n\n\n\n\n\nTip\n\n\n\nYou don’t know what Streamlit can do. Streamlit doesn’t know what you want.\nBut, we’ve gotta start somewhere.\nSo let’s learn a bit. Once you know what it can do,\nyou’ll finally know what you can make it do (with AI’s help).\n\n\n\n\n\n\n\n\nTipHow learn to use a new Python package?\n\n\n\n\nWhat is Streamlit, and where is its API reference and official documentation?\nWhat can Streamlit do — what kinds of apps or problems is it best at solving?\nWhat small examples or experiments can I build to quickly discover and learn its core features?\n\n\n\n\nStart with the official docs and examples — skim the Streamlit docs homepage and gallery to get a mental map of what’s possible before diving into code.\nLearn by doing small experiments — build micro-apps (e.g., one with a button, one with a chart) to turn reading into muscle memory.\n\nE.g., create app1.py, app2.py files each to test and run some micro streamlit apps.\n\nRead code, not just tutorials — explore community demos or open-source Streamlit apps to see how others structure layouts, manage state, and handle inputs.\nIterate with feedback loops — run streamlit run app.py often and tweak one thing at a time; immediate visual feedback accelerates understanding.\nReflect and generalize — after each mini-project, note what patterns repeat (e.g., sidebar widgets, caching, layout control) to build knowledge for future tools.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prototyping an app with `streamlit`</span>"
    ]
  },
  {
    "objectID": "chapter3.html#prototype-a-streamlit-app",
    "href": "chapter3.html#prototype-a-streamlit-app",
    "title": "4  Prototyping an app with streamlit",
    "section": "4.5 Prototype a Streamlit app",
    "text": "4.5 Prototype a Streamlit app\nHere is an example.\n\n\n\nAn Streamlit Example\n\n\n\nTry to build a dashboard displaying the financial metrics interactively.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Prototyping an app with `streamlit`</span>"
    ]
  },
  {
    "objectID": "chapter4.html",
    "href": "chapter4.html",
    "title": "5  Build Applications with LLMs and AI Feature",
    "section": "",
    "text": "5.1 Review the Difference of API vs. Chat in AI Tools\nMany of you have already used AI chat tools like ChatGPT or Gemini Chat to ask questions, write code snippets, or brainstorm ideas. That’s the user experience — you’re communicating with the model to get answers.\nBut when you start using LLMs and AI agents for development, the perspective changes completely. Instead of talking to the AI, you’re now building with it. You’re no longer just a user — you become a developer who leverages the model’s power through APIs to create tools, automate workflows, or build intelligent apps for others to use.\nThe table below compares OpenAI’s ChatGPT and Google’s Gemini platforms, highlighting the difference between their APIs (used by developers to build applications) and their chat interfaces (used by end users to interact with the models).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Build Applications with LLMs and AI Feature</span>"
    ]
  },
  {
    "objectID": "chapter4.html#review-the-difference-of-api-vs.-chat-in-ai-tools",
    "href": "chapter4.html#review-the-difference-of-api-vs.-chat-in-ai-tools",
    "title": "5  Build Applications with LLMs and AI Feature",
    "section": "",
    "text": "Aspect\nOpenAI API\nChatGPT (OpenAI)\nGemini API\nGemini Chat\n\n\n\n\nType\nDeveloper API\nChat Interface\nDeveloper API\nChat Interface\n\n\nPurpose\nBuild apps or tools using GPT models (e.g., GPT-4).\nChat directly with GPT models for writing, coding, or learning.\nBuild apps or workflows using Gemini models.\nChat naturally with Gemini for assistance or ideas.\n\n\nHow It’s Used\nThrough code (Python, JS, etc.).\nThrough a chat interface (web or app).\nThrough code (Google AI Studio or Vertex AI).\nThrough chat (Gemini web app, Workspace integration).\n\n\nUsers\nDevelopers, researchers.\nGeneral users, educators, professionals.\nDevelopers, data teams.\nStudents, creators, general users.\n\n\nExample Use\nA developer calls GPT-4 via API to generate summaries or analyze data.\nYou ask “Explain this regression code.”\nA data app uses Gemini API to summarize Google Sheets data.\nYou ask Gemini, “Visualize this dataset for me.”\n\n\nOutput Control\nFully customizable — responses formatted via code.\nNatural text output in chat.\nFully customizable — can return text, JSON, or structured data.\nConversational responses, plain text or visuals.\n\n\nGoal\nBuild with the model.\nTalk to the model.\nBuild with the model.\nTalk to the model.\n\n\n\n\n\n\n\n\n\nWarningSummary\n\n\n\n\nAPIs are for developers — you use them to build apps with AI features for the end users.\nChat tools are for the end users — you chat with the model to get answers.\nOpenAI powers ChatGPT; Google powers Gemini; different ecosystems.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Build Applications with LLMs and AI Feature</span>"
    ]
  },
  {
    "objectID": "chapter4.html#lab-1-enhance-your-app-with-llm-powered-interpretation",
    "href": "chapter4.html#lab-1-enhance-your-app-with-llm-powered-interpretation",
    "title": "5  Build Applications with LLMs and AI Feature",
    "section": "5.2 Lab 1: Enhance Your App with LLM-Powered Interpretation",
    "text": "5.2 Lab 1: Enhance Your App with LLM-Powered Interpretation\nIn this lab, you will continue building your financial dashboard by integrating AI features with Google Gemini API.\n\n5.2.1 Get Started with Gemini API\nPlease sign in to Google AI Studio using your Google account https://ai.google.dev/aistudio.\n\n\n5.2.2 Create your Google Gemini API Key\nGoogle has a free tier for the Gemini API that provides limited usage for development and experimentation.\nYou can obtain a free API key using your Google account:\n\nhttps://aistudio.google.com/api-keys\n\n\nPlease delete your key if not in use. Keep it secure, and never share or publish your key.\n\n\n5.2.3 Lab: Run A Simple Gemini Use Case\nCheck out the page &lt;https://aistudio.google.com/app/&gt; for a simple use case of how to use Gemini API with Python (see the code example below)\n# get started with Gemini using Python\n# You can find the code from Google AI Studio\nfrom google import genai\n\n# modify this line of code with your own api\nclient = genai.Client()\n\nresponse = client.models.generate_content(\n    model=\"gemini-3-flash-preview\",\n    contents=\"Explain how AI works in a few words\",\n)\n\nprint(response.text)\nCreate a Colab notebook (e.g., gemini.ipynb) and copy the sample code above. Then modidy the following line with your api_key to run the sample code.\n# modify this line of code in the previous code section.\nclient = genai.Client(api_key=\"your_actual_api_key_here\")\n\nI successfully tested the Gemini Use Case.\n\n\n\n5.2.4 Prompt engineering\nA prompt is the input text or query given to a generative AI model to instruct it on what to do.\n\ne.g., “Write a Python function to calculate the average of a list.”\n\nIn simple terms, prompt engineering is about communicating effectively with AI. It’s the skill of writing prompts so the large language models (LLMs) understands your intent, context, and background, and can respond accurately and usefully.\nIn other words:\n\nPrompt engineering = communication skills with LLMs.\n\n\n\n\n\n\n\nNote\n\n\n\nYou can explore prompt ideas for the Gemini API in Google AI studio. https://ai.google.dev/gemini-api/prompts\n\n\n\n\n5.2.5 Bad vs Good Prompts\nHere is a number of examples showing how vague prompts differs from well-engineered ones. AI can understand and act only as well as you communicate.\n\n\n\n\n\n\n\n\n\nTask\nBad Prompt\nGood Prompt\nWhy It’s Better\n\n\n\n\nAsk for code\n“Write some Python code for data.”\n“Write a Python function using pandas to read a CSV file, clean missing values, and calculate the average of each column.”\nGives clear context, specific goal, and tools to use.\n\n\nExplain concept\n“Explain machine learning.”\n“Explain what machine learning is for a high school student using everyday examples.”\nSpecifies audience and tone, making the response more focused.\n\n\nGenerate text\n“Write about climate change.”\n“Write a 3-paragraph summary of climate change causes and impacts, suitable for a classroom presentation.”\nDefines length, scope, and audience.\n\n\nData science task\n“Analyze this dataset.”\n“Analyze this dataset to find the top 5 products by sales, and visualize the trend over time using matplotlib.”\nSpecifies the goal, method, and output format.\n\n\n\n\n\n5.2.6 Lab: Design a Value-Adding AI Prompt for Your Dashboard\nYour financial metrics dashboard already allows users to select tickers and view several metrics. Now, your goal is to design a prompt that integrates a LLM from Gemini to provide AI-generated insights that add value for the users of the dashboard.\n\nDesign your prompt with clear intent and context.\n\nThe prompt should generate something useful for the dashboard user.\nIntegrate your prompt into your streamlit app. You can build on the simple use case you successfully tested earlier and try integrating it into your streamlit app using Copilot.\nTest your prompt in the dashboard to ensure it gives clear, relevant, and user-friendly outputs.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Build Applications with LLMs and AI Feature</span>"
    ]
  },
  {
    "objectID": "chapter4.html#lab-2-add-an-ai-agent-to-your-dashboard-optional",
    "href": "chapter4.html#lab-2-add-an-ai-agent-to-your-dashboard-optional",
    "title": "5  Build Applications with LLMs and AI Feature",
    "section": "5.3 Lab 2: Add an AI Agent to your Dashboard (optional)",
    "text": "5.3 Lab 2: Add an AI Agent to your Dashboard (optional)\n\n5.3.1 What Is an AI Agent?\nAn AI Agent is a system that uses an AI model—often a Large Language Model (LLM)—to reason, decide, and take actions toward a goal. Instead of just producing text, an agent can plan what to do next, call external tools (like APIs or databases), and use the results to continue reasoning. In other words, it’s not just “answering questions,” it’s doing things.\nThink of an AI agent as an intelligent assistant that:\n\nUnderstands your goal (through natural language),\nDecides what steps to take,\nExecutes tools or code to gather information or perform tasks,\nReflects on results, and produces a final answer or output.\n\n\n\n5.3.2 5.3.2 Difference Between an LLM and an AI Agent\nA Large Language Model (LLM) (such as GPT-4o, Gemini, or Claude) is fundamentally a language reasoning engine. It is trained on massive amounts of text to understand, generate, and reason with language.\nOn its own, an LLM operates only on the information provided in its input and what it learned during training. While modern models are far more capable than earlier ones, they do not inherently have awareness of the live world unless they are explicitly connected to external tools or data sources.\nHistorically, this limitation was described using knowledge cutoff dates (the point in time up to which the model was trained). While these still exist, they are less important today because many LLMs can now access real-time information when tools are enabled.\nExamples of approximate training cutoffs (for context only):\n\nGPT-4 (OpenAI): ~April 2023\n\nGPT-4o (OpenAI): ~October 2023\n\nGemini 2.0 Flash (Google DeepMind): ~August 2024\n\nClaude 3.5 Sonnet (Anthropic): ~April 2024\n\n\n5.3.2.1 Key Distinction\n\n\n\n\n\n\n\n\nConcept\nWhat It Does\nExample\n\n\n\n\nLLM\nUnderstands and generates text\nAnswer “What is artificial intelligence?”\n\n\nAI Agent\nUses an LLM plus tools and actions to achieve goals\nFetch recent AAPL news, analyze trends, and summarize insights\n\n\n\nAn LLM alone cannot:\n\nFetch live news\n\nQuery external APIs\n\nExecute code\n\nInteract with apps or systems\n\nIt can only reason over text it receives.\nAn AI Agent, on the other hand, wraps an LLM with:\n\nTool access (browsers, APIs, databases, code execution)\nDecision-making logic (when and how to use tools)\nMulti-step planning and task execution\n\n\n\n5.3.2.2 Modern Perspective: “Agentic” LLMs\nToday, many LLMs are described as agentic. This does not mean the model itself is an agent, but that it is designed to:\n\nDecide when to call external tools\nRetrieve real-time information\nExecute code or workflows\nBreak complex tasks into multiple steps and act on them\n\nIn short:\n\nLLM = reasoning engine\nAI Agent = reasoning engine + tools + actions + goals\n\nThis distinction is crucial when designing real-world AI systems that need to do more than just generate text.\nIn this mini exercise, you’ll see how an mini AI agent can make simple decisions before taking action. The agent will use an LLM to reason about the company’s sector — if the selected ticker belongs to an IT or technology company, the model will decide to fetch the latest news using yfiance tools. Otherwise, it will decide to do nothing and respond that no action is needed. This simple logic from checks, decides, acts or not, illustrates how agents can combine reasoning and tool use to behave intelligently, even in small, rule-based workflows.\nYou can use the following code as an example for one-shot prompting to make your AI feature agentic (LLM + tool usage to fetch real-time news).\n\n\n\n\n\n\nNoteOne-shot prompting\n\n\n\nOne-shot prompting is a prompt engineering technique where you show the model a single example (input + desired output) so it learns the pattern before handling your task. It is useful when you want the model to mimic a format or style with minimal guidance.\n\n\n# mini_agent_two_actions.py\n# pip install yfinance google-genai\n# you may test run it in Colab to start\n# then revise and consider embed it in your streamlit app.\nimport os, json, yfinance as yf\nfrom google import genai\n\nclient = genai.Client(api_key=\"your--google--api\")\nMODEL = \"gemini-2.5-flash\"\n\ndef fetch_news(ticker: str, limit: int = 5):\n    \"\"\"Tool: get latest news for a ticker using yfinance.\"\"\"\n    try:\n        news = yf.Ticker(ticker).news or []\n    except Exception:\n        news = []\n    items = []\n    for n in news[:limit]:\n        item_data = {\n            \"title\": n.get(\"content\", {}).get(\"title\"),\n            \"link\": n.get(\"content\", {}).get(\"clickThroughUrl\"),\n        }\n        # Filter out entries with no title and link\n        if item_data.get(\"title\") and item_data.get(\"link\"):\n          items.append(item_data)\n    print(items) # Keep print for debugging as in original code\n    return items\n\ndef decide_action(ticker: str):\n    prompt = f\"\"\"\nYou can take ONE of two actions for a given stock ticker.\n\n1. fetch_news — if the ticker belongs to an IT or technology company\n   (e.g., AAPL, MSFT, GOOG, META, NVDA, AMZN, etc.)\n2. none — for any other sector or if you're unsure.\n\nReturn STRICT JSON only:\n{{\"action\": \"fetch_news\" | \"none\", \"args\": {{\"ticker\": \"&lt;T&gt;\", \"limit\": &lt;int&gt;}}}}\nUse ticker=\"{ticker}\".\n\"\"\"\n    resp = client.models.generate_content(\n        model=MODEL,\n        contents=prompt,\n        config={\"response_mime_type\":\"application/json\"}\n    )\n    return json.loads(resp.text)\n\ndef final_answer(ticker: str, action: str, items=None):\n    if action == \"none\":\n        return f\"The ticker **{ticker}** is not in the IT sector — no action taken.\"\n    prompt = f\"\"\"\nSummarize the latest news for {ticker} using ONLY this JSON list:\n{json.dumps(items, indent=2)}\n\nReturn short markdown:\n- 2–3 key insights\n- One-line sentiment (Positive/Neutral/Negative)\n- Sources as bullet links: [Publisher — Title](URL)\n\"\"\"\n    resp = client.models.generate_content(\n        model=MODEL,\n        contents=prompt,\n        config={\"response_mime_type\": \"text/plain\"}\n    )\n    return resp.text\n\ndef run(ticker=\"AAPL\"):\n    plan = decide_action(ticker)\n    action = plan.get(\"action\", \"none\")\n    args = plan.get(\"args\", {})\n    if action == \"fetch_news\":\n        items = fetch_news(args.get(\"ticker\", ticker), int(args.get(\"limit\", 5)))\n        answer = final_answer(ticker, action, items)\n    else:\n        answer = final_answer(ticker, action)\n    print(answer)\n\nif __name__ == \"__main__\":\n    #run(\"AAPL\")   # should fetch news\n    run(\"TLT\")  # try a non-IT ticker for \"none\" action",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Build Applications with LLMs and AI Feature</span>"
    ]
  },
  {
    "objectID": "chapter5.html",
    "href": "chapter5.html",
    "title": "6  Lab - Business Metrics Practice (optional)",
    "section": "",
    "text": "6.1 Business Metrics\nThe most important question for decision-makers is: What changes can we make in our business processes right now to increase revenue, improve profitability, or reduce risk?\nBusiness metrics provide the foundation for answering that question. By tracking and analyzing key metrics, generally grouped into revenue, profitability, and risk, we can identify where change is needed, measure its potential impact, and guide smarter decisions for immediate and long-term improvement.\nA good company should track all three types of metrics.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Lab - Business Metrics Practice (optional)</span>"
    ]
  },
  {
    "objectID": "chapter5.html#business-metrics",
    "href": "chapter5.html#business-metrics",
    "title": "6  Lab - Business Metrics Practice (optional)",
    "section": "",
    "text": "Revenue metrics focus on sales and marketing performance — they’re outward-facing and show how effectively a company generates income.\n\nEverything that relates directly or indirectly to selling is a revenue metric.\n\nProfitability metrics measure how efficiently a company turns resources into profit through production, logistics, and operations.\n\nExamples include how often the company is unable to meet urgent customer requests and loses sales because of insufficient production or inventory.\nThese metrics highlight how effectively the business controls costs and minimizes waste to maximize profit.\n\nRisk metrics assess financial stability and exposure, mainly used by risk managers, creditors, and investors. Such as:\n\nNet cash out: how many months can the company survive at the present burn rate?\n\nChurn rate.\nDebts.\n\n\n\n\n\n\n\n\n\nImportantDynamic Metrics\n\n\n\nIt’s important to remember that useful business metrics are dynamic — they may change over time therefore they should always be measured and interpreted within a specific time frame.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Lab - Business Metrics Practice (optional)</span>"
    ]
  },
  {
    "objectID": "chapter5.html#lab-business-metrics-dashboard",
    "href": "chapter5.html#lab-business-metrics-dashboard",
    "title": "6  Lab - Business Metrics Practice (optional)",
    "section": "6.2 Lab: Business Metrics Dashboard",
    "text": "6.2 Lab: Business Metrics Dashboard\nPlease download and read the case description:\n\nCase Study Business Metrics - Ad Analyses.pdf\nad_table.csv\n\nThe goal of this lab is to look at a few ad campaigns, analyze their current performance, identify key business metrics and create a dashboard to report them.\n\n6.2.1 Requirements\nFrom a business perspective, specifically, you are asked to:\n\nIdentify critical business metrics and distinguish them from mere data\nCalculate the metrics that are important and worth reporting\nDesign a streamlit dashboard to display these metrics interactively\nInclude explanations alongside each metric using text components\n\nEnsure users understand what each metric represents and how it reflects overall business performance.\nIn short, don’t just calculate metrics — demonstrate that you can interpret their meaning and implications for decision-making.\nExplanations can be dynamically generated using an AI-powered feature.\n\nClean and well-organized code following the recommended workflow below.\n\n\n\n\n\n\n\nTip\n\n\n\nDeveloping key business metrics requires domain knowledge — understanding what drives the business. You can use EDA (Exploratory Data Analysis) and AI-powered Q&A to uncover key metrics worth tracking and reporting in the provided data.\n\n\n\n\n6.2.2 Recommended Workflow\nA structured workflow helps you move efficiently from exploration to production. It turns messy experimentation into reproducible, professional pipelines for real-world data projects.\n\nStep 1. Rapid EDA in a .ipynb\n\nCreate and Use a eda.ipynb notebook to inspect data quality, clean data, develop metrics, test feature ideas, and prototype formulas and metrics.\n\n\n\nStep 2. Refactor into a .py metrics module\n\nMove code (cleaning, feature engineering, metric formulas) from the notebook into functions in metrics_utils.py. Add docstrings, type hints, and tests.\n\n\n\nStep 3. Import the module and design the Streamlit UI\n\nIn app.py, import metrics_utils, design and build a streamlit app that display key metrics that you identified. Choose proper features in the streamlit.\n\n\n\n\n\n\n\nNoteWhy this workflow works (the rationale)?\n\n\n\n\nMirrors the real development cycle: notebooks for development and experimentation, .py modules for stable logic ready for release, and Streamlit for production presentation.\nReusability: Metric functions can be reused across future apps and analyses.\nTestability: Logic in .py is easy to test (if name == “main”:).\nMaintainability: Update formulas once in the module, not in multiple places.\n\n\n\n\n\n\n6.2.3 Project Folder Structure\ncreate a adsanalyses folder in your home directory with the files structured below.\n# suggested folder structure under your home directory\nadsanalyses/\n├─ eda.ipynb        # your EDA\n├─ metrics_utils.py # functions for load data, and calculating metrics\n├─ app.py           # your streamlit app\n└─ ad_table.csv\nThank you!",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Lab - Business Metrics Practice (optional)</span>"
    ]
  }
]